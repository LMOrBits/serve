{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from flask.cli import load_dotenv\n",
    "import pytest\n",
    "from pathlib import Path\n",
    "import json\n",
    "import tempfile\n",
    "import shutil\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow import MlflowClient\n",
    "from serve.utils.mlflow.config import MLFlowConfig, MLflowModelConfigManager\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_docker_path = Path(\"../\").resolve()\n",
    "print(mlflow_docker_path)\n",
    "env_file = mlflow_docker_path / \"scripts/dev/mlflow\"  / \"config.env\"\n",
    "\n",
    "load_dotenv(env_file)\n",
    "mlflow_port = os.getenv(\"MLFLOW_PORT\")\n",
    "minio_access_key = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "minio_secret_key = os.getenv(\"MINIO_SECRET_ACCESS_KEY\")\n",
    "mlflow_port\n",
    "Path(env_file).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5001'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-04 23:20:31.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mInitialized model configuration manager with config path: config.json\u001b[0m\n",
      "\u001b[32m2025-03-04 23:20:31.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mInitialized MLflow model configuration manager\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: ./\n",
      "MLflow client: <mlflow.tracking.client.MlflowClient object at 0x12b322a20>\n",
      "Experiments: [<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1741078047476, experiment_id='1', last_update_time=1741078047476, lifecycle_stage='active', name='test_experiment', tags={}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1741021252438, experiment_id='0', last_update_time=1741021252438, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "tracking_uri = f\"http://localhost:{mlflow_port}/\"\n",
    "mlflow_client = MlflowClient(tracking_uri=tracking_uri, registry_uri=tracking_uri)\n",
    "config_path = \"./\"\n",
    "print(f\"Config path: {config_path}\")\n",
    "print(f\"MLflow client: {mlflow_client}\")\n",
    "experiments = mlflow_client.search_experiments()\n",
    "print(f\"Experiments: {experiments}\")\n",
    "model_config_manager = MLflowModelConfigManager(mlflow_client=mlflow_client, config_path=config_path)\n",
    "model_dir = model_config_manager.add_model(\"rag_model\", alias=\"champion\" , artifact_path=\"model_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-04 23:21:40.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mInitialized LLaMA CPP server manager\u001b[0m\n",
      "\u001b[32m2025-03-04 23:21:40.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mInitialized model configuration manager with config path: /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/config.json\u001b[0m\n",
      "\u001b[32m2025-03-04 23:21:40.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mInitialized MLflow model configuration manager\u001b[0m\n",
      "\u001b[32m2025-03-04 23:21:40.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.experiment_tracker.mlflow.mlflow_llamacpp.manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mInitialized model manager successfully\u001b[0m\n",
      "\u001b[32m2025-03-04 23:21:40.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.experiment_tracker.mlflow.mlflow_llamacpp.manager\u001b[0m:\u001b[36madd_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mSuccessfully added model qa_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:21:40.160\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/src/serve/servers/llamacpp'), 'serve', 'MODEL_PATH=/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/models/qa_model/model_path/artifacts', 'SERVER_PORTS=8000', 'UI_PORT=8080', 'MODEL_NAME=model.gguf', 'MODEL_ID=qa_model']\u001b[0m\n",
      "\u001b[32m2025-03-04 23:22:10.993\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m33\u001b[0m - \u001b[31m\u001b[1m\u001b[32mtask: [serve] echo \"Starting LlamaCpp server and waiting for it to be ready...\"\n",
      "\u001b[0m\u001b[32mtask: [serve] container_id=$(docker run -d \\\n",
      "  --name lmorbits-llamacpp-qa_model \\\n",
      "  -p 8000:8000 \\\n",
      "  -p 8080:8080 \\\n",
      "  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/models/qa_model/model_path/artifacts:/models \\\n",
      "  ghcr.io/ggerganov/llama.cpp:server \\\n",
      "  -m /models/model.gguf)\n",
      "\n",
      "while ! docker logs $container_id 2>&1 | grep -q \"GET /health 127.0.0.1 200\"; do\n",
      "  echo \"Loading model and starting server...\"\n",
      "  docker logs --tail 10 $container_id\n",
      "  sleep 1\n",
      "done\n",
      "echo \"LlamaCpp server is ready!\"\n",
      "\n",
      "\u001b[0mllama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   61 tensors\n",
      "llama_model_loader: - type q5_0:  166 tensors\n",
      "llama_model_loader: - type q8_0:   15 tensors\n",
      "llama_model_loader: - type q4_K:   16 tensors\n",
      "llama_model_loader: - type q6_K:   14 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 98.87 MiB (6.17 BPW) \n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "\u001b[0m\n",
      "\u001b[32m2025-03-04 23:22:10.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mStarting LlamaCpp server and waiting for it to be ready...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "LlamaCpp server is ready!\n",
      "\u001b[0m\n",
      "\u001b[32m2025-03-04 23:22:10.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36mserve\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mStarted server for model ID: qa_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:22:10.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mAdded new server instance with model ID: qa_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:22:10.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.experiment_tracker.mlflow.mlflow_llamacpp.manager\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m176\u001b[0m - \u001b[1mStarted serving model qa_model on ports 8000/8080\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from serve.experiment_tracker.mlflow.mlflow_llamacpp.manager import ModelManager\n",
    "manager = ModelManager(\n",
    "  mlflow_client=mlflow_client,\n",
    "  config_path=Path(\"./c\").resolve().absolute()\n",
    ")\n",
    "manager.add_model(\"qa_model\", alias=\"champion\", artifact_path=\"model_path\")\n",
    "manager.add_serve(\"qa_model\", server_port=8000, ui_port=8080, gguf_relative_path=\"model_path/artifacts/model.gguf\")\n",
    "# manager.stop_serve_model(\"qa_model\")\n",
    "# manager.delete_model(\"qa_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-04 23:23:20.252\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36mload_model_config\u001b[0m:\u001b[36m159\u001b[0m - \u001b[33m\u001b[1mNo configuration found for model: rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:20.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36mcheck_for_update\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mNo local version found for rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:20.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36madd_model\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mModel rag_model is already up to date\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:20.253\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36mload_model_config\u001b[0m:\u001b[36m159\u001b[0m - \u001b[33m\u001b[1mNo configuration found for model: rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:20.253\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36mget_model_path\u001b[0m:\u001b[36m460\u001b[0m - \u001b[31m\u001b[1mError getting path for rag_model: No path found for model rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:20.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36madd_model\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFound model version: 1 for rag_model\u001b[0m\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:01<00:00,  4.50it/s]   \n",
      "\u001b[32m2025-03-04 23:23:21.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36mdownload_artifacts\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mDownloaded artifacts to /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/models/rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:21.627\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36mload_model_config\u001b[0m:\u001b[36m159\u001b[0m - \u001b[33m\u001b[1mNo configuration found for model: rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:21.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36m_ensure_model_dir_exists\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mCreated model directory: /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:21.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36msave_config\u001b[0m:\u001b[36m214\u001b[0m - \u001b[1mConfiguration saved successfully\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:21.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36mupdate_config\u001b[0m:\u001b[36m235\u001b[0m - \u001b[1mUpdated configuration for model: rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:21.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36mupdate_model_info\u001b[0m:\u001b[36m271\u001b[0m - \u001b[1mUpdated model info for rag_model with run_id fdc268fd82824c90a5e46b2e673e1913\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:21.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.experiment_tracker.mlflow.mlflow_llamacpp.manager\u001b[0m:\u001b[36madd_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mSuccessfully added model rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:21.629\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/src/serve/servers/llamacpp'), 'serve', 'MODEL_PATH=/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/models/rag_model/model_path/artifacts', 'SERVER_PORTS=8001', 'UI_PORT=8081', 'MODEL_NAME=model.gguf', 'MODEL_ID=rag_model']\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:52.440\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m33\u001b[0m - \u001b[31m\u001b[1m\u001b[32mtask: [serve] echo \"Starting LlamaCpp server and waiting for it to be ready...\"\n",
      "\u001b[0m\u001b[32mtask: [serve] container_id=$(docker run -d \\\n",
      "  --name lmorbits-llamacpp-rag_model \\\n",
      "  -p 8001:8000 \\\n",
      "  -p 8081:8080 \\\n",
      "  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/models/rag_model/model_path/artifacts:/models \\\n",
      "  ghcr.io/ggerganov/llama.cpp:server \\\n",
      "  -m /models/model.gguf)\n",
      "\n",
      "while ! docker logs $container_id 2>&1 | grep -q \"GET /health 127.0.0.1 200\"; do\n",
      "  echo \"Loading model and starting server...\"\n",
      "  docker logs --tail 10 $container_id\n",
      "  sleep 1\n",
      "done\n",
      "echo \"LlamaCpp server is ready!\"\n",
      "\n",
      "\u001b[0mllama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   61 tensors\n",
      "llama_model_loader: - type q5_0:  166 tensors\n",
      "llama_model_loader: - type q8_0:   15 tensors\n",
      "llama_model_loader: - type q4_K:   16 tensors\n",
      "llama_model_loader: - type q6_K:   14 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 98.87 MiB (6.17 BPW) \n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:52.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mStarting LlamaCpp server and waiting for it to be ready...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "Loading model and starting server...\n",
      "LlamaCpp server is ready!\n",
      "\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:52.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36mserve\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mStarted server for model ID: rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:52.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mAdded new server instance with model ID: rag_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:23:52.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.experiment_tracker.mlflow.mlflow_llamacpp.manager\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m176\u001b[0m - \u001b[1mStarted serving model rag_model on ports 8001/8081\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.add_model(\"rag_model\", alias=\"champion\", artifact_path=\"model_path\")\n",
    "manager.add_serve(\"rag_model\", server_port=8001, ui_port=8081, gguf_relative_path=\"model_path/artifacts/model.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-04 23:25:29.829\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/src/serve/servers/llamacpp'), 'stop', 'MODEL_ID=qa_model']\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mlmorbits-llamacpp-qa_model\n",
      "\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m200\u001b[0m - \u001b[1mStopped server instance with model ID: qa_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.030\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/src/serve/servers/llamacpp'), 'delete', 'MODEL_ID=qa_model']\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mlmorbits-llamacpp-qa_model\n",
      "lmorbits-llamacpp-qa_model\n",
      "\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36mdelete\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1mDeleted server instance with model ID: qa_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36mdelete_model\u001b[0m:\u001b[36m303\u001b[0m - \u001b[1mDeleted model directory: /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/models/qa_model\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.model_config\u001b[0m:\u001b[36msave_config\u001b[0m:\u001b[36m214\u001b[0m - \u001b[1mConfiguration saved successfully\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.utils.mlflow.config\u001b[0m:\u001b[36mdelete_model\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mRemoved qa_model from configuration\u001b[0m\n",
      "\u001b[32m2025-03-04 23:25:40.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.experiment_tracker.mlflow.mlflow_llamacpp.manager\u001b[0m:\u001b[36mdelete_model\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mDeleted model qa_model\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.delete_model(\"qa_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path(\"./c/models/model_path/artifacts/model.gguf\")\\\n",
    "  .resolve().absolute()\n",
    "p.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/packages/serve/notebooks/c/models/model_path/artifacts')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
