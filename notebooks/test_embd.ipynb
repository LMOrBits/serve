{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serve.servers.embedding.main import EmbeddingManager\n",
    "from serve.servers.llamacpp.serve import LlamaCppServer\n",
    "from dotenv import load_dotenv\n",
    "from mlflow import MlflowClient\n",
    "from pathlib import Path\n",
    "import os\n",
    "load_dotenv(\".env\")\n",
    "client = MlflowClient(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "manager = EmbeddingManager(Path(\"./\").resolve() /\"models\", client)\n",
    "llama_server = LlamaCppServer(Path(\"./\").resolve() / \"models\", client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manager.new_model_status(\"rag_embeddings\", \"champion\")\n",
    "llama_server.new_model_status(\"rag_model\", \"champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 01:15:50.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36mupdate_model\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mUpdating model rag_model with alias champion\u001b[0m\n",
      "\u001b[32m2025-05-10 01:15:50.145\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/src/serve/servers/llamacpp'), 'delete', 'MODEL_ID=rag_model']\u001b[0m\n",
      "\u001b[32m2025-05-10 01:15:50.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m2c699f642f26\n",
      "2c699f642f26\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-10 01:15:50.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mDeleting old model rag_model from /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/models\u001b[0m\n",
      "\u001b[32m2025-05-10 01:15:50.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mDownloading model rag_model from mlflow\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  4.52it/s]   \n",
      "\u001b[32m2025-05-10 01:15:51.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mModel rag_model downloaded to /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/models/rag_model\u001b[0m\n",
      "\u001b[32m2025-05-10 01:15:51.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.llamacpp.serve\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mRunning model rag_model with alias champion\u001b[0m\n",
      "\u001b[32m2025-05-10 01:15:51.739\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/src/serve/servers/llamacpp'), 'serve', 'MODEL_ID=rag_model', 'MODEL_PATH=/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/models/rag_model/model_path/artifacts', 'PORT=8080']\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:22.529\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m33\u001b[0m - \u001b[31m\u001b[1m\u001b[32mtask: [serve] echo \"Starting LlamaCpp server and waiting for it to be ready...\"\n",
      "\u001b[0m\u001b[32mtask: [serve] if [ \"$(docker ps -q --filter \"status=exited\" -f name=lmorbits-llamacpp-rag_model)\" ]; then\n",
      "  docker start lmorbits-llamacpp-rag_model\n",
      "  container_id=$(docker ps -aqf \"name=lmorbits-llamacpp-rag_model\")\n",
      "else\n",
      "  container_id=$(docker run -d \\\n",
      "    --name lmorbits-llamacpp-rag_model \\\n",
      "    -p 8080:8080 \\\n",
      "    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/models/rag_model/model_path/artifacts:/models \\\n",
      "    ghcr.io/ggerganov/llama.cpp:server \\\n",
      "    -m /models/model.gguf)\n",
      "fi\n",
      "\n",
      "echo \"üïê Waiting for LlamaCpp server to become healthy...\"\n",
      "while ! docker logs $container_id 2>&1 | grep -q \"GET /health 127.0.0.1 200\"; do\n",
      "  echo \"‚è≥ Still starting...\"\n",
      "  docker logs --tail 10 $container_id\n",
      "  sleep 1\n",
      "done\n",
      "\n",
      "echo \"‚úÖ LlamaCpp server is ready!\"\n",
      "\n",
      "\u001b[0mllama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   61 tensors\n",
      "llama_model_loader: - type q5_0:  166 tensors\n",
      "llama_model_loader: - type q8_0:   15 tensors\n",
      "llama_model_loader: - type q4_K:   16 tensors\n",
      "llama_model_loader: - type q6_K:   14 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 98.87 MiB (6.17 BPW) \n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "<|im_start|>user\n",
      "Hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "'\n",
      "main: server is listening on http://0.0.0.0:8080 - starting the main loop\n",
      "srv  update_slots: all slots are idle\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:22.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mStarting LlamaCpp server and waiting for it to be ready...\n",
      "üïê Waiting for LlamaCpp server to become healthy...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚è≥ Still starting...\n",
      "‚úÖ LlamaCpp server is ready!\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llama_server.update_model(\"rag_model\", \"champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 01:16:25.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.embedding.main\u001b[0m:\u001b[36mupdate_model\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mUpdating model rag_embeddings with alias champion\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:25.560\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/src/serve/servers/embedding'), 'delete', 'MODEL_NAME=rag_embeddings']\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:25.603\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m33\u001b[0m - \u001b[31m\u001b[1m\u001b[32mtask: [delete] if [ \"$(docker ps -q -f name=lmorbits-embedding-rag_embeddings)\" ]; then \n",
      "  if [ \"$(docker ps -q --filter \"status=running\" -f name=lmorbits-embedding-rag_embeddings)\" ]; then\n",
      "    echo \"Stopping lmorbits-embedding-rag_embeddings\"\n",
      "    docker stop lmorbits-embedding-rag_embeddings\n",
      "  fi\n",
      "  echo \"Removing lmorbits-embedding-rag_embeddings\"\n",
      "  docker rm lmorbits-embedding-rag_embeddings\n",
      "else\n",
      "  echo \"lmorbits-embedding-rag_embeddings is not running\"\n",
      "fi\n",
      "\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:25.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mlmorbits-embedding-rag_embeddings is not running\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:25.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.embedding.main\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mDeleting old model rag_embeddings from /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/models\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:25.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.embedding.main\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mDownloading model rag_embeddings from mlflow\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 653.33it/s] \n",
      "\u001b[32m2025-05-10 01:16:25.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.embedding.main\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mModel rag_embeddings downloaded to /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/models/rag_embeddings\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:25.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve.servers.embedding.main\u001b[0m:\u001b[36madd_serve\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mRunning model rag_embeddings with alias champion\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:25.679\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/src/serve/servers/embedding'), 'serve', 'MODEL_NAME=rag_embeddings', 'MODEL_PATH=/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/models/rag_embeddings/serve']\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:48.381\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m33\u001b[0m - \u001b[31m\u001b[1m\u001b[32mtask: [serve] if [ \"$(docker ps -q --filter \"status=running\" -f name=lmorbits-embedding-rag_embeddings)\" ]; then\n",
      "  echo \"lmorbits-embedding-rag_embeddings is already running\"\n",
      "elif [ \"$(docker ps -q --filter \"status=exited\" -f name=lmorbits-embedding-rag_embeddings)\" ]; then\n",
      "  echo \"Starting lmorbits-embedding-rag_embeddings\"\n",
      "  docker start lmorbits-embedding-rag_embeddings\n",
      "else\n",
      "  echo \"Building lmorbits-embedding-image image\"\n",
      "  docker build -t lmorbits-embedding-image -f Dockerfile .\n",
      "  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image\n",
      "fi\n",
      "# health check on /health endpoint\n",
      "until curl -s http://localhost:1111/health | grep -q \"ok\"; do\n",
      "  echo \"Waiting for lmorbits-embedding-rag_embeddings to be ready...\"\n",
      "  sleep 1\n",
      "done\n",
      "\n",
      "\u001b[0m#0 building with \"orbstack\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 317B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for ghcr.io/astral-sh/uv:python3.13-bookworm-slim\n",
      "#2 DONE 0.7s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 102B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [1/6] FROM ghcr.io/astral-sh/uv:python3.13-bookworm-slim@sha256:d0f50b72ce818caf18da58e8d41cb9f2cb6ef21cd42a12d46efa8e52c17ff87c\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 190.20kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [3/6] COPY pyproject.toml .\n",
      "#6 CACHED\n",
      "\n",
      "#7 [4/6] COPY uv.lock .\n",
      "#7 CACHED\n",
      "\n",
      "#8 [5/6] RUN uv sync\n",
      "#8 CACHED\n",
      "\n",
      "#9 [2/6] WORKDIR /app\n",
      "#9 CACHED\n",
      "\n",
      "#10 [6/6] COPY . .\n",
      "#10 CACHED\n",
      "\n",
      "#11 exporting to image\n",
      "#11 exporting layers done\n",
      "#11 writing image sha256:13aa3e85d59daa24f510d7aad0d262b9e238456ad5b8a7a164025d21e66edec8 done\n",
      "#11 naming to docker.io/library/lmorbits-embedding-image done\n",
      "#11 DONE 0.0s\n",
      "\n",
      "View build details: docker-desktop://dashboard/build/orbstack/orbstack/lzsta192wghpcwgk2em6pvve3\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-10 01:16:48.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mBuilding lmorbits-embedding-image image\n",
      "40aafa0a9256fd708a0957ffb0c6dcf56f32d9160cfe9ff00cc7b20977986257\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "Waiting for lmorbits-embedding-rag_embeddings to be ready...\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.update_model(\"rag_embeddings\", \"champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 00:54:35.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/src/serve/servers/embedding'), 'serve', 'MODEL_NAME=rag_embeddings', 'MODEL_PATH=/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/notebooks/em/rag_embeddings/serve']\u001b[0m\n",
      "\u001b[32m2025-05-10 00:54:35.491\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m33\u001b[0m - \u001b[31m\u001b[1m\u001b[32mtask: [serve] if [ \"$(docker ps -q --filter \"status=running\" -f name=lmorbits-embedding-rag_embeddings)\" ]; then\n",
      "  echo \"lmorbits-embedding-rag_embeddings is already running\"\n",
      "elif [ \"$(docker ps -q --filter \"status=exited\" -f name=lmorbits-embedding-rag_embeddings)\" ]; then\n",
      "  echo \"Starting lmorbits-embedding-rag_embeddings\"\n",
      "  docker start lmorbits-embedding-rag_embeddings\n",
      "else\n",
      "  echo \"Building lmorbits-embedding-image image\"\n",
      "  docker build -t lmorbits-embedding-image -f Dockerfile .\n",
      "  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image\n",
      "fi\n",
      "# health check on /health endpoint\n",
      "until curl -s http://localhost:1111/health | grep -q \"ok\"; do\n",
      "  echo \"Waiting for lmorbits-embedding-rag_embeddings to be ready...\"\n",
      "  sleep 1\n",
      "done\n",
      "\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[32m2025-05-10 00:54:35.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mlmorbits-embedding-rag_embeddings is already running\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "manager.add_serve(model_name=\"rag_embeddings\", alias=\"champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.new_model_status(\"rag_embeddings\", \"champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 00:08:56.056\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1m['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/src/serve/servers/embedding/main.py'), 'serve']\u001b[0m\n",
      "\u001b[32m2025-05-10 00:08:56.081\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mserve._cli.task\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m33\u001b[0m - \u001b[31m\u001b[1m\u001b[31mtask: Failed to parse ../src/serve/servers/embedding/main.py:\n",
      "yaml: line 12: mapping values are not allowed in this context\n",
      "\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['task', '--dir', PosixPath('/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/serve/src/serve/servers/embedding/main.py'), 'serve'], returncode=109, stdout='', stderr='\\x1b[31mtask: Failed to parse ../src/serve/servers/embedding/main.py:\\nyaml: line 12: mapping values are not allowed in this context\\n\\x1b[0m')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.task_cli.run(\"serve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
